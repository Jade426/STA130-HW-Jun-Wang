{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3f33959",
   "metadata": {},
   "source": [
    "#Question 1\n",
    "\n",
    "-The key factor for testable ideas is the presence of measurable and observable data. Without actual data to support comparisons, we cannot establish a framework for statistical hypothesis testing. \n",
    "\n",
    "-The criteria for a good null hypothesis is that it is specific, testable, and based on a clear, measurable premise. It should present a neutral statement that can be tested and potentially rejected based on statistical evidence. Null hypothesis generally assumes no effect or no difference between groups or conditions.\n",
    "\n",
    "-Null hypothesis is H0, which represents a statement of no effect, no difference. It assumes that any observed differences are due to random chance. It is essentially a statement of ‚Äúno change‚Äù or ‚Äúno relationship‚Äù between variables.\n",
    "\n",
    "-Alternative hypothesis is Ha, which is the claim we are testing for. We assume that something happens. And it is what we want to prove as being significant. It suggests that there is an actual effect, difference, or relationship between variables. \n",
    "\n",
    "-Their difference is that the null hypothesis serves as a baseline, and the alternative hypothesis is what you're testing for potential significance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334ac3e4",
   "metadata": {},
   "source": [
    "#Question 1 Chat History with ChatGPT\n",
    "\n",
    "please provide me a summary of our chat\n",
    "ChatGPT saysÔºö\n",
    "ChatGPT\n",
    "Here‚Äôs a summary of our chat:\n",
    "\n",
    "You explained your understanding of testable ideas and the criteria for a good null hypothesis, emphasizing the importance of measurable data, a specific and testable null hypothesis, and the difference between the null (H0) and alternative (Ha) hypotheses. I confirmed that your understanding is correct and added some details to enhance it, focusing on the neutrality and specificity of the null hypothesis, as well as the baseline role it plays in hypothesis testing. I also highlighted how the alternative hypothesis represents what the researcher aims to prove and how both hypotheses create a framework for statistical evaluation.\n",
    "\n",
    "https://chatgpt.com/share/6704791e-b6d8-8002-9b0f-b83fa803a9fe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d8e378",
   "metadata": {},
   "source": [
    "#Question 2\n",
    "-xi represents individual data points or values we collect in our sample. For instance, if we‚Äôre measuring the heights of five people, each person's height is an xi.\n",
    "\n",
    "-x bar is the average of the sample, which means we add up all the individual xi values and divide by the number of data points. It gives us an idea of the sample's typical value.\n",
    "\n",
    "-Œº is the true average of the entire population we‚Äôre interested in. It‚Äôs like the ultimate average that we want to know but can‚Äôt measure directly because it requires data from everyone in the population.\n",
    "\n",
    "-Œº0 is a specific value that we assume the population average (Œº) might be, usually under the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914cf8b7",
   "metadata": {},
   "source": [
    "#Question 2 Chat Hitory with ChatGPT\n",
    "\n",
    "please provide me a summary of our chat history\n",
    "ChatGPT saysÔºö\n",
    "ChatGPT\n",
    "Here's a summary of our chat history:\n",
    "\n",
    "Data Analysis Projects: You‚Äôve been working on data analysis projects, including:\n",
    "\n",
    "A dataset on Animal Crossing characters, exploring details about the villagers.\n",
    "The Titanic dataset, where you performed summary analyses.\n",
    "A vaccine data analysis assignment for AliTech, where you're evaluating vaccine effectiveness using statistical methods. Specifically, you're focusing on calculating the mean of differences for a paired t-test.\n",
    "Academic Interests and Goals:\n",
    "\n",
    "You are interested in becoming a statistician and a psychologist.\n",
    "Your professor advised against overgeneralization in assignments, emphasizing the importance of context, especially when discussing historical societies like ancient Greece.\n",
    "Statistical Concepts:\n",
    "\n",
    "You asked about understanding statistical terms like \n",
    "ùë•\n",
    "ùëñ\n",
    "x \n",
    "i\n",
    "‚Äã\n",
    " , \n",
    "ùë•\n",
    "Àâ\n",
    "x\n",
    "Àâ\n",
    " , \n",
    "ùúá\n",
    "Œº, and \n",
    "ùúá\n",
    "0\n",
    "Œº \n",
    "0\n",
    "‚Äã\n",
    "  and worked on refining your explanations for these terms.\n",
    "Throughout our conversations, you‚Äôve been focused on improving your data analysis skills and gaining a deeper understanding of statistical concepts.\n",
    "\n",
    "https://chatgpt.com/share/67048275-9b10-8002-afd0-55c6bd43e30b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2eea78",
   "metadata": {},
   "source": [
    "#Question 3\n",
    "\n",
    "When we calculate a p-value, we start by assuming that the null hypothesis is true. This means we‚Äôre imagining a scenario where there‚Äôs no effect or no difference‚Äîessentially, that everything we‚Äôre testing for doesn‚Äôt actually exist in the real world. Under this assumption, we can then create a sampling distribution, which shows us all the possible outcomes we might expect to see just by random chance.\n",
    "\n",
    "The p-value tells us how likely the extreme value would be presented if the null hypothesis were true. In other words, it‚Äôs a way of checking whether our observed data is unusual or surprising in a world where there really is no effect. If the p-value is very low, it suggests that an unlikely-happened value is being easily took out from the random sample. An unlikely-happened thing really happens under the null hypothesis, this maks us question whether the null hypothesis is actually true. \n",
    "If the p-value is high, our data fits comfortably within the range of expected outcomes if the null hypothesis were true, which means a likely-happened thing really happens (which is normal), so we don‚Äôt have strong evidence against it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7005e9ff",
   "metadata": {},
   "source": [
    "#Question 4\n",
    "\n",
    "A smaller p-value suggests that the data we observed is very unlikely if the null hypothesis were true. We can consider the sampling distribution of the test statistic under the null hypothesis. It represents all the possible values our test statistic could take, assuming the null hypothesis is true and everything is happening by random chance.\n",
    "\n",
    "When we calculate a test statistic such as a mean difference based on our sample, we see where it falls within this sampling distribution. A small p-value indicates that our test statistic is far out in the tail of this distribution, which means that it's a rare outcome if the null hypothesis were true.\n",
    "\n",
    "The further away our observed result is from what we'd expect under the null hypothesis, the less likely it is that this outcome happened just by chance. In this way, a small p-value makes the null hypothesis look \"more ridiculous\" and less likely to happen, because it implies that, under the assumption that the null hypothesis is true, our observed result is extremely improbable. This improbability pushes us to doubt the null hypothesis and lean towards the possibility that the effect or difference we're testing for actually exists.\n",
    "\n",
    "For example, consider testing the effectiveness of a new vaccine, where the null hypothesis claims it has no effect. After calculating the test statistic (like the mean difference in infection rates) and comparing it to the sampling distribution under the null hypothesis, a small p-value suggests that this result is unlikely due to random chance. This improbability makes us doubt the null hypothesis, leaning toward the conclusion that the vaccine likely has a significant effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5b05388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated p-value: 0.0007\n"
     ]
    }
   ],
   "source": [
    "#Question 5\n",
    "#To investigate whether kissing couples show a tendency to tilt their heads to the right, we can simulate a p-value under the null hypothesis ùêª0, which assumes no preference for head tilt direction:\n",
    "\n",
    "#H0: p=0.5 Ha:p!=0.5\n",
    "\n",
    "#-Simulation Setup: Using a ‚Äú50/50 coin-flipping‚Äù model, we simulate 124 couples, with each couple having an equal chance of tilting their head to the right or left.\n",
    "\n",
    "#-Outcome Count: We run multiple simulations (e.g., 10,000) and count the number of simulations where 80 or more couples tilt their heads to the right, as observed in the study (64.5% tilted right).\n",
    "\n",
    "#-Calculate the p-value: The p-value is the proportion of simulations where 80 or more couples tilt right, indicating the likelihood of observing this result if the null hypothesis is true.\n",
    "\n",
    "#-Interpretation: According to the provided evidence table, a small p-value would suggest strong evidence against ùêª0. For example, if ùëù‚â§0.01, this would be considered strong evidence against the null hypothesis, suggesting that the observed head tilt preference is unlikely to be due to random chance alone.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "num_couples = 124  # Total number of couples\n",
    "observed_right_tilts = 80  # Number of couples who tilted to the right\n",
    "num_simulations = 10000  # Number of simulations to run\n",
    "p_right = 0.5  # Probability of tilting right under the null hypothesis\n",
    "\n",
    "simulated_counts = np.random.binomial(num_couples, p_right, num_simulations)\n",
    "\n",
    "p_value = np.mean(simulated_counts >= observed_right_tilts)\n",
    "\n",
    "print(\"Simulated p-value:\", p_value)\n",
    "\n",
    "#As a result, we reject H0 and conclude Ha. Since p-value 0.0007, is less than 0.001, we have very strong evidence against the null hypothesis, \n",
    "#and say that p!=0.5, shich means the head tilted to left or right is not a random preference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f10bb4",
   "metadata": {},
   "source": [
    "#Question 6\n",
    "A smaller p-value does not definitively prove that the null hypothesis is false. Instead, it provides evidence that the observed data is less likely if the null hypothesis were true, prompting us to question its validity. However, it does not offer absolute proof.\n",
    "\n",
    "In the case of Fido from the video, a p-value can‚Äôt definitively prove Fido's innocence or guilt. A low p-value suggests that the evidence against Fido being innocent (the null hypothesis) is strong, but it doesn't confirm guilt beyond all doubt. Conversely, a high p-value doesn't prove innocence but rather suggests insufficient evidence to reject the null hypothesis.\n",
    "\n",
    "P-values do not provide conclusive proof; they measure the strength of evidence. There is no specific threshold at which a p-value can definitively establish guilt or innocence because statistical significance does not equate to absolute certainty.\n",
    "\n",
    "Moreover, ther might be Type I and Type II error. \n",
    "A Type I error occurs when we reject the null hypothesis (ùêª0) when it is actually true.\n",
    "A Type II error occurs when we fail to reject the null hypothesis when the alternative hypothesis (ùêªùëé) is actually true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c1013ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Tailed Test (greater than):\n",
      "Number of Simulations: 10000\n",
      "Number of simulated statistics under H0 that are greater than or equal to the observed statistic: 3730\n",
      "p-value (one-tailed): 0.373\n"
     ]
    }
   ],
   "source": [
    "#Question 7\n",
    "#Code after change:\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)  \n",
    "patient_data = pd.DataFrame({'HealthScoreChange': np.random.normal(0, 1, 10)})\n",
    "\n",
    "np.random.seed(1)  \n",
    "number_of_simulations = 10000\n",
    "n_size = len(patient_data)\n",
    "population_parameter_value_under_H0 = 0.5\n",
    "\n",
    "IncreaseProportionSimulations_underH0random = np.zeros(number_of_simulations)\n",
    "for i in range(number_of_simulations):\n",
    "    random_improvement = np.random.choice([0, 1], size=n_size, replace=True)\n",
    "    IncreaseProportionSimulations_underH0random[i] = random_improvement.mean()\n",
    "\n",
    "observed_statistic = (patient_data['HealthScoreChange'] > 0).mean()\n",
    "\n",
    "SimStats_greater_than_ObsStat = IncreaseProportionSimulations_underH0random >= observed_statistic\n",
    "p_value = SimStats_greater_than_ObsStat.sum() / number_of_simulations\n",
    "\n",
    "print(\"One-Tailed Test (greater than):\")\n",
    "print(\"Number of Simulations:\", number_of_simulations)\n",
    "print(\"Number of simulated statistics under H0 that are greater than or equal to the observed statistic:\", SimStats_greater_than_ObsStat.sum())\n",
    "print(\"p-value (one-tailed):\", p_value)\n",
    "\n",
    "\n",
    "#Explanation of the changes:\n",
    "#The p-value calculation now uses SimStats_greater_than_ObsStat, \n",
    "#which only considers simulations where the simulated statistic is greater than or equal to the observed statistic.\n",
    "\n",
    "#The p-value is smaller than the original one. \n",
    "#Because the one-tailed test only considers deviations in one specific direction. \n",
    "#In a two-tailed test, we assess whether the observed statistic is significantly different (either greater or lesser) from the null hypothesis value, doubling the extreme regions we‚Äôre interested in. \n",
    "#This means that the p-value includes the probabilities of deviations on both sides of the distribution.\n",
    "#In contrast, a one-tailed test focuses only on deviations in one direction‚Äîeither greater than or less than the null hypothesis value‚Äîdepending on our hypothesis. \n",
    "#This halves the area we‚Äôre evaluating under the curve, leading to a lower p-value for a given observed statistic if it falls in the specified tail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f252a88a",
   "metadata": {},
   "source": [
    "#Question 7 Chat History with ChatGPT\n",
    "please provide me a summary of our chat\n",
    "ChatGPT saysÔºö\n",
    "ChatGPT\n",
    "Certainly! Here‚Äôs a summary of our chat:\n",
    "\n",
    "You shared Python code for a hypothesis test involving health score changes. Initially, the code was set up for a two-tailed test to evaluate if there was a difference in health score improvements under a null hypothesis.\n",
    "\n",
    "You asked for help in modifying the code for a one-tailed test. I provided a modified version of the code, which checks if simulated statistics are only greater than or equal to the observed statistic (assuming you are testing for a positive change).\n",
    "\n",
    "You encountered an error, NameError: name 'patient_data' is not defined, which indicated that the patient_data DataFrame was missing. I suggested ensuring the dataset was loaded or created before running the code and provided an example of how to define patient_data with a random set of health score changes.\n",
    "\n",
    "Let me know if you'd like any additional details or further assistance!\n",
    "\n",
    "https://chatgpt.com/share/670f2bba-9bc8-8002-a8fe-f264238c6b64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78842143",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 8\n",
    "\n",
    "#Null Hypothesis (ùêª0): The proportion of students who can correctly identify the order of pouring is due to random guessing, meaning ùëù=0.5.\n",
    "#Alternative Hypothesis (ùêªùëé): The proportion of students who can correctly identify the order of pouring is greater than random guessing, meaning ùëù>0.5\n",
    "\n",
    "#Since we have a sample size of 80 and 49 correct identifications, our observed proportion (ùëù hat) is 49/80=0.6125. \n",
    "#We will perform a one-sided hypothesis test to assess whether this proportion is significantly greater than 0.5, indicating an ability beyond random guessing.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "num_students = 80\n",
    "observed_correct = 49\n",
    "p_null = 0.5  # under the null hypothesis\n",
    "num_simulations = 10000\n",
    "\n",
    "simulated_counts = np.random.binomial(num_students, p_null, num_simulations)\n",
    "simulated_proportions = simulated_counts / num_students\n",
    "\n",
    "observed_proportion = observed_correct / num_students\n",
    "p_value = np.mean(simulated_proportions >= observed_proportion)\n",
    "\n",
    "print(\"Simulated p-value:\", p_value)\n",
    "\n",
    "#Since this p-value is less than  the significance level of 0.05, \n",
    "#which suggests that achieving the observed proportion by random chance alone is unlikely, providing evidence against the null hypothesis.\n",
    "#There is enough evidence to reject ùêª0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac153cf",
   "metadata": {},
   "source": [
    "#Question 9\n",
    "Yes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
